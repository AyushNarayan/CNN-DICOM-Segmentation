{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function,absolute_import, unicode_literals\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "#plt.rcParams['image.cmap'] = 'gist_earth'\n",
    "import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "import shutil\n",
    "from collections import OrderedDict\n",
    "import logging\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importing Data :: Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_images_input = np.load('/home/ctuser/Desktop/Semantic_Seg/data/datatrain_images_input__big_1.npy')\n",
    "ground_truth_images = np.load('/home/ctuser/Desktop/Semantic_Seg/data/datatrain_images_groundtruth_big_1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "offset = np.ones_like(train_images_input,dtype=np.int16)\n",
    "offset = offset*1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_images_input+=offset\n",
    "train_images_input = train_images_input.astype('float32')\n",
    "ground_truth_images = ground_truth_images.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BaseDataProvider(object):\n",
    "    \"\"\"\n",
    "    This class is used to import, preprocessing of data\n",
    "    before feeding into Convolutional neural networks.\n",
    "    It also create labels into same fashion.\n",
    "    \"\"\"\n",
    "    \n",
    "    #channels = 1\n",
    "    #n_class = 2\n",
    "    def __init__(self,data,label,a_min=None,a_max=None,channels =1,n_class =2):\n",
    "        self.a_min = a_min if a_min is not None else -np.inf\n",
    "        self.a_max = a_max if a_max is not None else np.inf\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.file_count = data.shape[0]\n",
    "        self.n_class=n_class\n",
    "        self.channels = channels\n",
    "    \n",
    "    def _next_data(self):\n",
    "        idx = np.random.choice(self.file_count)\n",
    "        return self.data[idx], self.label[idx]\n",
    "    \n",
    "    def _load_data_and_label(self):\n",
    "        data, label = self._next_data()\n",
    "        \n",
    "        train_data = self._process_data(data)\n",
    "        labels = self._process_labels(label)\n",
    "        \n",
    "        train_data, labels = self._postprocess_data(train_data, labels)\n",
    "        \n",
    "        nx = data.shape[1]\n",
    "        ny = data.shape[0]\n",
    "        \n",
    "        return train_data.reshape(1, ny, nx, self.channels), labels.reshape(1, ny, nx, self.n_class)\n",
    "    \n",
    "    def _process_labels(self, label):\n",
    "        if self.n_class==2:\n",
    "            nx = label.shape[1]\n",
    "            ny = label.shape[0]\n",
    "            labels = np.zeros((ny,nx,self.n_class),dtype=np.float32)\n",
    "            one = np.ones_like(labels[...,0],dtype=np.float32)\n",
    "            labels[...,0] = one - label\n",
    "            labels[...,1] = label\n",
    "            return labels\n",
    "        \n",
    "        return label\n",
    "    \n",
    "    def _process_data(self, data):\n",
    "        data = np.clip(data, self.a_min, self.a_max)\n",
    "        data = data-np.amin(data)    \n",
    "        data = data/np.amax(data)\n",
    "        return data\n",
    "    \n",
    "    def _postprocess_data(self,data,labels):\n",
    "        \"\"\"\n",
    "        Post processing can be done to make it more easier \n",
    "        for CNN to work and give better accuracy.\n",
    "        \n",
    "        \"\"\"\n",
    "        return data, labels\n",
    "    \n",
    "    def __call__(self,n):\n",
    "        train_data, labels = self._load_data_and_label()\n",
    "        nx = train_data.shape[1]\n",
    "        ny = train_data.shape[2]\n",
    "        \n",
    "        X = np.zeros((n, nx, ny, self.channels))\n",
    "        Y = np.zeros((n, nx, ny, self.n_class))\n",
    "        \n",
    "        X[0] = train_data\n",
    "        Y[0] = labels\n",
    "        \n",
    "        for i in range(1,n):\n",
    "            train_data, labels = self._load_data_and_label()\n",
    "            X[i] = train_data\n",
    "            Y[i] = labels\n",
    "            \n",
    "        \n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mydata = BaseDataProvider(data=train_images_input, label=ground_truth_images,channels=1,n_class=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test = mydata(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, sharey=True, figsize=(8,4))\n",
    "ax[0].imshow(X_test[0,...,0], aspect=\"auto\")\n",
    "ax[1].imshow(Y_test[0,...,0], aspect=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Building Convolutional Networks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Defining Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_prediction(x_test, y_test, prediction, save=False):\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    test_size = x_test.shape[0]\n",
    "    fig, ax = plt.subplots(test_size, 3, figsize=(12,12), sharey=True, sharex=True)\n",
    "    ax = np.atleast_2d(ax)\n",
    "    for i in range(test_size):\n",
    "        cax = ax[i, 0].imshow(x_test[i,...,0])\n",
    "        plt.colorbar(cax, ax=ax[i,0])\n",
    "        cax = ax[i, 1].imshow(y_test[i, ..., 1])\n",
    "        plt.colorbar(cax, ax=ax[i,1])\n",
    "        pred = prediction[i, ..., 1]\n",
    "        #pred -= np.amin(pred)                           ## recheck this :: might create some errors later.\n",
    "        #pred /= np.amax(pred)\n",
    "        cax = ax[i, 2].imshow(pred)\n",
    "        plt.colorbar(cax, ax=ax[i,2])\n",
    "        if i==0:\n",
    "            ax[i, 0].set_title(\"x\")\n",
    "            ax[i, 1].set_title(\"y\")\n",
    "            ax[i, 2].set_title(\"pred\")\n",
    "    #fig.tight_layout()\n",
    "    \n",
    "    if save:\n",
    "        fig.savefig(save)\n",
    "    else:\n",
    "        fig.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_to_shape(data, shape):\n",
    "    \"\"\"\n",
    "    Crops the array to the given image shape by removing the border (expects a tensor of shape [batches, nx, ny, channels].\n",
    "    \n",
    "    :param data: the array to crop\n",
    "    :param shape: the target shape\n",
    "    \"\"\"\n",
    "    offset0 = (data.shape[1] - shape[1])//2\n",
    "    offset1 = (data.shape[2] - shape[2])//2\n",
    "    if data.shape[1] == shape[1]:\n",
    "        return data\n",
    "    else:\n",
    "        return data[:, offset0:(-offset0), offset1:(-offset1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_rgb(img):\n",
    "    \"\"\"\n",
    "    Converts the given array into a RGB image. If the number of channels is not\n",
    "    3 the array is tiled such that it has 3 channels. Finally, the values are\n",
    "    rescaled to [0,255) \n",
    "    \n",
    "    :param img: the array to convert [nx, ny, channels]\n",
    "    \n",
    "    :returns img: the rgb image [nx, ny, 3]\n",
    "    \"\"\"\n",
    "    img = np.atleast_3d(img)\n",
    "    channels = img.shape[2]\n",
    "    if channels < 3:\n",
    "        img = np.tile(img, 3)\n",
    "    \n",
    "    img[np.isnan(img)] = 0\n",
    "    img -= np.amin(img)\n",
    "    img /= np.amax(img)\n",
    "    img *= 255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_rate(predictions, labels):\n",
    "    \"\"\"\n",
    "    Return the error rate based on dense predictions and 1-hot labels.\n",
    "    \"\"\"\n",
    "    \n",
    "    return 100.0 - (100.0 * np.sum(np.argmax(predictions, 3) == np.argmax(labels, 3)) /\n",
    "                    (predictions.shape[0]*predictions.shape[1]*predictions.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_image_summary(img, idx=0):\n",
    "    \"\"\"\n",
    "    Make an image summary for 4d tensor image with index idx\n",
    "    \"\"\"\n",
    "    \n",
    "    V = tf.slice(img, (0, 0, 0, idx), (1, -1, -1, 1))\n",
    "    V -= tf.reduce_min(V)\n",
    "    V /= tf.reduce_max(V)\n",
    "    V *= 255\n",
    "    \n",
    "    img_w = tf.shape(img)[1]\n",
    "    img_h = tf.shape(img)[2]\n",
    "    V = tf.reshape(V, tf.stack((img_w, img_h, 1)))\n",
    "    V = tf.transpose(V, (2, 0, 1))\n",
    "    V = tf.reshape(V, tf.stack((-1, img_w, img_h, 1)))\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_img_prediction(data, gt, pred):\n",
    "    \"\"\"\n",
    "    Combines the data, grouth thruth and the prediction into one rgb image\n",
    "    \n",
    "    :param data: the data tensor\n",
    "    :param gt: the ground thruth tensor\n",
    "    :param pred: the prediction tensor\n",
    "    \n",
    "    :returns img: the concatenated rgb image \n",
    "    \"\"\"\n",
    "    ny = pred.shape[2]\n",
    "    ch = data.shape[3]\n",
    "    img = np.concatenate(to_rgb((crop_to_shape(data, pred.shape).reshape(-1, ny, ch)), \n",
    "                          to_rgb(crop_to_shape(gt[..., 1], pred.shape).reshape(-1, ny, 1)), \n",
    "                          to_rgb(pred[..., 1].reshape(-1, ny, 1))), axis=1)\n",
    "    return img\n",
    "\n",
    "def save_image(img, path):\n",
    "    \"\"\"\n",
    "    Writes the image to disk\n",
    "    \n",
    "    :param img: the rgb image to save\n",
    "    :param path: the target path\n",
    "    \"\"\"\n",
    "    Image.fromarray(img.round().astype(np.uint8)).save(path, 'JPEG', dpi=[300,300], quality=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **layers_initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape, stddev=0.1):\n",
    "    initial = tf.truncated_normal(shape, stddev=stddev)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def weight_variable_devonc(shape, stddev=0.1):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=stddev))\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W,keep_prob_):\n",
    "    conv_2d = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='VALID')\n",
    "    return tf.nn.dropout(conv_2d, keep_prob_)\n",
    "\n",
    "def deconv2d(x, W,stride):\n",
    "    x_shape = tf.shape(x)\n",
    "    output_shape = tf.stack([x_shape[0], x_shape[1]*2, x_shape[2]*2, x_shape[3]//2])\n",
    "    return tf.nn.conv2d_transpose(x, W, output_shape, strides=[1, stride, stride, 1], padding='VALID')\n",
    "\n",
    "def max_pool(x,n):\n",
    "    return tf.nn.max_pool(x, ksize=[1, n, n, 1], strides=[1, n, n, 1], padding='VALID')\n",
    "\n",
    "def crop_and_concat(x1,x2):\n",
    "    x1_shape = tf.shape(x1)\n",
    "    x2_shape = tf.shape(x2)\n",
    "    # offsets for the top left corner of the crop\n",
    "    offsets = [0, (x1_shape[1] - x2_shape[1]) // 2, (x1_shape[2] - x2_shape[2]) // 2, 0]\n",
    "    size = [-1, x2_shape[1], x2_shape[2], -1]\n",
    "    x1_crop = tf.slice(x1, offsets, size)\n",
    "    return tf.concat([x1_crop, x2], 3)   \n",
    "\n",
    "def pixel_wise_softmax(output_map):\n",
    "    exponential_map = tf.exp(output_map)\n",
    "    evidence = tf.add(exponential_map,tf.reverse(exponential_map,[False,False,False,True]))\n",
    "    return tf.div(exponential_map,evidence, name=\"pixel_wise_softmax\")\n",
    "\n",
    "def pixel_wise_softmax_2(output_map):\n",
    "    exponential_map = tf.exp(output_map)\n",
    "    sum_exp = tf.reduce_sum(exponential_map, 3, keep_dims=True)\n",
    "    tensor_sum_exp = tf.tile(sum_exp, tf.stack([1, 1, 1, tf.shape(output_map)[3]]))\n",
    "    return tf.div(exponential_map,tensor_sum_exp)\n",
    "\n",
    "def cross_entropy(y_,output_map):\n",
    "    return -tf.reduce_mean(y_*tf.log(tf.clip_by_value(output_map,1e-10,1.0)), name=\"cross_entropy\")\n",
    "#     return tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(output_map), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conv_net(x, keep_prob, channels, n_class, layers=3, features_root=16, filter_size=3, pool_size=2, summaries=False):\n",
    "    \"\"\"\n",
    "    Creates a new convolutional unet for the given parametrization.\n",
    "    \n",
    "    :param x: input tensor, shape [?,nx,ny,channels]\n",
    "    :param keep_prob: dropout probability tensor\n",
    "    :param channels: number of channels in the input image\n",
    "    :param n_class: number of output labels\n",
    "    :param layers: number of layers in the net\n",
    "    :param features_root: number of features in the first layer\n",
    "    :param filter_size: size of the convolution filter\n",
    "    :param pool_size: size of the max pooling operation\n",
    "    :param summaries: Flag if summaries should be created\n",
    "    \"\"\"\n",
    "    \n",
    "    logging.info(\"Layers {layers}, features {features}, filter size {filter_size}x{filter_size},pool size: {pool_size}x{pool_size}\".format(layers=layers,\n",
    "                                                                                                           features=features_root,\n",
    "                                                                                                           filter_size=filter_size,\n",
    "                                                                                                           pool_size=pool_size))\n",
    "    # Placeholder for the input image\n",
    "    nx = tf.shape(x)[1]\n",
    "    ny = tf.shape(x)[2]\n",
    "    x_image = tf.reshape(x, tf.stack([-1,nx,ny,channels]))\n",
    "    in_node = x_image\n",
    "    batch_size = tf.shape(x_image)[0]\n",
    " \n",
    "    weights = []\n",
    "    biases = []\n",
    "    convs = []\n",
    "    pools = OrderedDict()\n",
    "    deconv = OrderedDict()\n",
    "    dw_h_convs = OrderedDict()\n",
    "    up_h_convs = OrderedDict()\n",
    "    paddings=[[0,0],[1,1],[1,1],[0,0]]\n",
    "    in_size = 1000\n",
    "    size = in_size\n",
    "    # down layers\n",
    "    for layer in range(0, layers):\n",
    "        features = 2**layer*features_root\n",
    "        stddev = np.sqrt(2 / (filter_size**2 * features))\n",
    "        if layer == 0:\n",
    "            w1 = weight_variable([filter_size, filter_size, channels, features], stddev)\n",
    "        else:\n",
    "            w1 = weight_variable([filter_size, filter_size, features//2, features], stddev)\n",
    "            \n",
    "        w2 = weight_variable([filter_size, filter_size, features, features], stddev)\n",
    "        b1 = bias_variable([features])\n",
    "        b2 = bias_variable([features])\n",
    "        \n",
    "        in_node = tf.pad(in_node,paddings,\"CONSTANT\")\n",
    "        conv1 = conv2d(in_node, w1, keep_prob)\n",
    "        tmp_h_conv = tf.nn.relu(conv1 + b1)\n",
    "        tmp_h_conv = tf.pad(tmp_h_conv,paddings,\"CONSTANT\")\n",
    "        conv2 = conv2d(tmp_h_conv, w2, keep_prob)\n",
    "        dw_h_convs[layer] = tf.nn.relu(conv2 + b2)\n",
    "        \n",
    "        weights.append((w1, w2))\n",
    "        biases.append((b1, b2))\n",
    "        convs.append((conv1, conv2))\n",
    "        \n",
    "        size -= 4\n",
    "        if layer < layers-1:\n",
    "            pools[layer] = max_pool(dw_h_convs[layer], pool_size)\n",
    "            in_node = pools[layer]\n",
    "            size /= 2\n",
    "        \n",
    "    in_node = dw_h_convs[layers-1]\n",
    "        \n",
    "    # up layers\n",
    "    for layer in range(layers-2, -1, -1):\n",
    "        \n",
    "        features = 2**(layer+1)*features_root\n",
    "        stddev = np.sqrt(2 / (filter_size**2 * features))\n",
    "        \n",
    "        wd = weight_variable_devonc([pool_size, pool_size, features//2, features], stddev)\n",
    "        bd = bias_variable([features//2])\n",
    "        h_deconv = tf.nn.relu(deconv2d(in_node, wd, pool_size) + bd)\n",
    "        h_deconv_concat = crop_and_concat(dw_h_convs[layer], h_deconv)\n",
    "        deconv[layer] = h_deconv_concat\n",
    "        \n",
    "        w1 = weight_variable([filter_size, filter_size, features, features//2], stddev)\n",
    "        w2 = weight_variable([filter_size, filter_size, features//2, features//2], stddev)\n",
    "        b1 = bias_variable([features//2])\n",
    "        b2 = bias_variable([features//2])\n",
    "        \n",
    "        h_deconv_concat = tf.pad(h_deconv_concat,paddings,\"CONSTANT\")\n",
    "        conv1 = conv2d(h_deconv_concat, w1, keep_prob)\n",
    "        h_conv = tf.nn.relu(conv1 + b1)\n",
    "        h_conv = tf.pad(h_conv,paddings,\"CONSTANT\")\n",
    "        conv2 = conv2d(h_conv, w2, keep_prob)\n",
    "        in_node = tf.nn.relu(conv2 + b2)\n",
    "        up_h_convs[layer] = in_node\n",
    "\n",
    "        weights.append((w1, w2))\n",
    "        biases.append((b1, b2))\n",
    "        convs.append((conv1, conv2))\n",
    "        \n",
    "        size *= 2\n",
    "        size -= 4\n",
    "\n",
    "    # Output Map\n",
    "    weight = weight_variable([1, 1, features_root, n_class], stddev)\n",
    "    bias = bias_variable([n_class])\n",
    "    conv = conv2d(in_node, weight, tf.constant(1.0))\n",
    "    output_map = tf.nn.relu(conv + bias)\n",
    "    up_h_convs[\"out\"] = output_map\n",
    "    \n",
    "    if summaries:\n",
    "        for i, (c1, c2) in enumerate(convs):\n",
    "            tf.summary.image('summary_conv_%02d_01'%i, get_image_summary(c1))\n",
    "            tf.summary.image('summary_conv_%02d_02'%i, get_image_summary(c2))\n",
    "            \n",
    "        for k in pools.keys():\n",
    "            tf.summary.image('summary_pool_%02d'%k, get_image_summary(pools[k]))\n",
    "        \n",
    "        for k in deconv.keys():\n",
    "            tf.summary.image('summary_deconv_concat_%02d'%k, get_image_summary(deconv[k]))\n",
    "            \n",
    "        for k in dw_h_convs.keys():\n",
    "            tf.summary.histogram(\"dw_convolution_%02d\"%k + '/activations', dw_h_convs[k])\n",
    "\n",
    "        for k in up_h_convs.keys():\n",
    "            tf.summary.histogram(\"up_convolution_%s\"%k + '/activations', up_h_convs[k])\n",
    "            \n",
    "    variables = []\n",
    "    for w1,w2 in weights:\n",
    "        variables.append(w1)\n",
    "        variables.append(w2)\n",
    "        \n",
    "    for b1,b2 in biases:\n",
    "        variables.append(b1)\n",
    "        variables.append(b2)\n",
    "\n",
    "    \n",
    "    return output_map, variables, int(in_size - size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(object):\n",
    "    \"\"\"\n",
    "    A unet implementation\n",
    "    \n",
    "    :param channels: (optional) number of channels in the input image\n",
    "    :param n_class: (optional) number of output labels\n",
    "    :param cost: (optional) name of the cost function. Default is 'cross_entropy'\n",
    "    :param cost_kwargs: (optional) kwargs passed to the cost function. See Unet._get_cost for more options\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, channels=1, n_class=2, cost=\"cross_entropy\", cost_kwargs={}, **kwargs):\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.n_class = n_class\n",
    "        self.summaries = kwargs.get(\"summaries\", True)\n",
    "        \n",
    "        self.x = tf.placeholder(\"float\", shape=[None, None, None, channels])\n",
    "        self.y = tf.placeholder(\"float\", shape=[None, None, None, n_class])\n",
    "        self.keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n",
    "        \n",
    "        logits, self.variables, self.offset = create_conv_net(self.x, self.keep_prob, channels, n_class, **kwargs)\n",
    "        \n",
    "        self.cost = self._get_cost(logits, cost, cost_kwargs)\n",
    "        \n",
    "        self.gradients_node = tf.gradients(self.cost, self.variables)\n",
    "         \n",
    "        self.cross_entropy = tf.reduce_mean(cross_entropy(tf.reshape(self.y, [-1, n_class]),\n",
    "                                                          tf.reshape(pixel_wise_softmax_2(logits), [-1, n_class])))\n",
    "        \n",
    "        self.predicter = pixel_wise_softmax_2(logits)\n",
    "        self.correct_pred = tf.equal(tf.argmax(self.predicter, 3), tf.argmax(self.y, 3))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_pred, tf.float32))\n",
    "        \n",
    "    def _get_cost(self, logits, cost_name, cost_kwargs):\n",
    "        \"\"\"\n",
    "        Constructs the cost function, either cross_entropy, weighted cross_entropy or dice_coefficient.\n",
    "        Optional arguments are: \n",
    "        class_weights: weights for the different classes in case of multi-class imbalance\n",
    "        regularizer: power of the L2 regularizers added to the loss function\n",
    "        \"\"\"\n",
    "        \n",
    "        flat_logits = tf.reshape(logits, [-1, self.n_class])\n",
    "        flat_labels = tf.reshape(self.y, [-1, self.n_class])\n",
    "        if cost_name == \"cross_entropy\":\n",
    "            class_weights = cost_kwargs.pop(\"class_weights\", None)\n",
    "            \n",
    "            if class_weights is not None:\n",
    "                class_weights = tf.constant(np.array(class_weights, dtype=np.float32))\n",
    "        \n",
    "                weight_map = tf.multiply(flat_labels, class_weights)\n",
    "                weight_map = tf.reduce_sum(weight_map, axis=1)\n",
    "        \n",
    "                loss_map = tf.nn.softmax_cross_entropy_with_logits(flat_logits, flat_labels)\n",
    "                weighted_loss = tf.multiply(loss_map, weight_map)\n",
    "        \n",
    "                loss = tf.reduce_mean(weighted_loss)\n",
    "                \n",
    "            else:\n",
    "                loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=flat_logits, \n",
    "                                                                              labels=flat_labels))\n",
    "        elif cost_name == \"dice_coefficient\":\n",
    "            eps = 1e-5\n",
    "            prediction = pixel_wise_softmax_2(logits)\n",
    "            intersection = tf.reduce_sum(prediction * self.y)\n",
    "            union =  eps + tf.reduce_sum(prediction) + tf.reduce_sum(self.y)\n",
    "            loss = -(2 * intersection/ (union))\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"Unknown cost function: \"%cost_name)\n",
    "\n",
    "        regularizer = cost_kwargs.pop(\"regularizer\", None)\n",
    "        if regularizer is not None:\n",
    "            regularizers = sum([tf.nn.l2_loss(variable) for variable in self.variables])\n",
    "            loss += (regularizer * regularizers)\n",
    "            \n",
    "        return loss\n",
    "\n",
    "    def predict(self, model_path, x_test):\n",
    "        \"\"\"\n",
    "        Uses the model to create a prediction for the given data\n",
    "        \n",
    "        :param model_path: path to the model checkpoint to restore\n",
    "        :param x_test: Data to predict on. Shape [n, nx, ny, channels]\n",
    "        :returns prediction: The unet prediction Shape [n, px, py, labels] (px=nx-self.offset/2) \n",
    "        \"\"\"\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        with tf.Session() as sess:\n",
    "            # Initialize variables\n",
    "            sess.run(init)\n",
    "        \n",
    "            # Restore model weights from previously saved model\n",
    "            self.restore(sess, model_path)\n",
    "            \n",
    "            y_dummy = np.empty((x_test.shape[0], x_test.shape[1], x_test.shape[2], self.n_class))\n",
    "            prediction = sess.run(self.predicter, feed_dict={self.x: x_test, self.y: y_dummy, self.keep_prob: 1.})\n",
    "            \n",
    "        return prediction\n",
    "    \n",
    "    def save(self, sess, model_path):\n",
    "        \"\"\"\n",
    "        Saves the current session to a checkpoint\n",
    "        \n",
    "        :param sess: current session\n",
    "        :param model_path: path to file system location\n",
    "        \"\"\"\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "        save_path = saver.save(sess, model_path)\n",
    "        return save_path\n",
    "    \n",
    "    def restore(self, sess, model_path):\n",
    "        \"\"\"\n",
    "        Restores a session from a checkpoint\n",
    "        \n",
    "        :param sess: current session instance\n",
    "        :param model_path: path to file system checkpoint location\n",
    "        \"\"\"\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, model_path)\n",
    "        logging.info(\"Model restored from file: %s\" % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    \"\"\"\n",
    "    Trains a unet instance\n",
    "    \n",
    "    :param net: the unet instance to train\n",
    "    :param batch_size: size of training batch\n",
    "    :param optimizer: (optional) name of the optimizer to use (momentum or adam)\n",
    "    :param opt_kwargs: (optional) kwargs passed to the learning rate (momentum opt) and to the optimizer\n",
    "    \"\"\"\n",
    "    \n",
    "    prediction_path = \"prediction\"    ### to channge this before running......give number at the end.\n",
    "    verification_batch_size = 4\n",
    "    \n",
    "    def __init__(self, net, batch_size=1, optimizer=\"momentum\", opt_kwargs={}):\n",
    "        self.net = net\n",
    "        self.batch_size = batch_size\n",
    "        self.optimizer = optimizer\n",
    "        self.opt_kwargs = opt_kwargs\n",
    "        \n",
    "    def _get_optimizer(self, training_iters, global_step):\n",
    "        if self.optimizer == \"momentum\":\n",
    "            learning_rate = self.opt_kwargs.pop(\"learning_rate\", 0.2)\n",
    "            decay_rate = self.opt_kwargs.pop(\"decay_rate\", 0.95)\n",
    "            momentum = self.opt_kwargs.pop(\"momentum\", 0.2)\n",
    "            \n",
    "            self.learning_rate_node = tf.train.exponential_decay(learning_rate=learning_rate, \n",
    "                                                        global_step=global_step, \n",
    "                                                        decay_steps=training_iters,  \n",
    "                                                        decay_rate=decay_rate, \n",
    "                                                        staircase=True)\n",
    "            \n",
    "            optimizer = tf.train.MomentumOptimizer(learning_rate=self.learning_rate_node, momentum=momentum,\n",
    "                                                   **self.opt_kwargs).minimize(self.net.cost, \n",
    "                                                                                global_step=global_step)\n",
    "        elif self.optimizer == \"adam\":\n",
    "            learning_rate = self.opt_kwargs.pop(\"learning_rate\", 0.001)\n",
    "            self.learning_rate_node = tf.Variable(learning_rate)\n",
    "            \n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate_node, \n",
    "                                               **self.opt_kwargs).minimize(self.net.cost,\n",
    "                                                                     global_step=global_step)\n",
    "        \n",
    "        return optimizer\n",
    "        \n",
    "    def _initialize(self, training_iters, output_path, restore):\n",
    "        global_step = tf.Variable(0)\n",
    "        \n",
    "        self.norm_gradients_node = tf.Variable(tf.constant(0.0, shape=[len(self.net.gradients_node)]))\n",
    "        \n",
    "        if self.net.summaries:\n",
    "            tf.summary.histogram('norm_grads', self.norm_gradients_node)\n",
    "\n",
    "        tf.summary.scalar('loss', self.net.cost)\n",
    "        tf.summary.scalar('cross_entropy', self.net.cross_entropy)\n",
    "        tf.summary.scalar('accuracy', self.net.accuracy)\n",
    "\n",
    "        self.optimizer = self._get_optimizer(training_iters, global_step)\n",
    "        tf.summary.scalar('learning_rate', self.learning_rate_node)\n",
    "\n",
    "        self.summary_op = tf.summary.merge_all()        \n",
    "        init = tf.global_variables_initializer()\n",
    "        \n",
    "        prediction_path = os.path.abspath(self.prediction_path)\n",
    "        output_path = os.path.abspath(output_path)\n",
    "        \n",
    "        if not restore:\n",
    "            logging.info(\"Removing '{:}'\".format(prediction_path))\n",
    "            shutil.rmtree(prediction_path, ignore_errors=True)\n",
    "            logging.info(\"Removing '{:}'\".format(output_path))\n",
    "            shutil.rmtree(output_path, ignore_errors=True)\n",
    "        \n",
    "        if not os.path.exists(prediction_path):\n",
    "            logging.info(\"Allocating '{:}'\".format(prediction_path))\n",
    "            os.makedirs(prediction_path)\n",
    "        \n",
    "        if not os.path.exists(output_path):\n",
    "            logging.info(\"Allocating '{:}'\".format(output_path))\n",
    "            os.makedirs(output_path)\n",
    "        \n",
    "        return init\n",
    "\n",
    "    def train(self, data_provider, output_path, training_iters=10, epochs=100, dropout=0.75, display_step=1, restore=False, write_graph=False):\n",
    "        \"\"\"\n",
    "        Lauches the training process\n",
    "        \n",
    "        :param data_provider: callable returning training and verification data\n",
    "        :param output_path: path where to store checkpoints\n",
    "        :param training_iters: number of training mini batch iteration\n",
    "        :param epochs: number of epochs\n",
    "        :param dropout: dropout probability\n",
    "        :param display_step: number of steps till outputting stats\n",
    "        :param restore: Flag if previous model should be restored \n",
    "        :param write_graph: Flag if the computation graph should be written as protobuf file to the output path\n",
    "        \"\"\"\n",
    "        save_path = os.path.join(output_path, \"model.cpkt\")  ## ////..change the save path before running if you want to be in same path..////\n",
    "        if epochs == 0:\n",
    "            return save_path\n",
    "        \n",
    "        init = self._initialize(training_iters, output_path, restore)\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            if write_graph:\n",
    "                tf.train.write_graph(sess.graph_def, output_path, \"graph.pb\", False)\n",
    "            \n",
    "            sess.run(init)\n",
    "            \n",
    "            if restore:\n",
    "                ckpt = tf.train.get_checkpoint_state(output_path)\n",
    "                if ckpt and ckpt.model_checkpoint_path:\n",
    "                    self.net.restore(sess, ckpt.model_checkpoint_path)\n",
    "            \n",
    "            test_x, test_y = data_provider(self.verification_batch_size)\n",
    "            pred_shape = self.store_prediction(sess, test_x, test_y, \"_init\")\n",
    "            \n",
    "            summary_writer = tf.summary.FileWriter(output_path, graph=sess.graph)\n",
    "            logging.info(\"Start optimization\")\n",
    "            \n",
    "            avg_gradients = None\n",
    "            for epoch in range(epochs):\n",
    "                total_loss = 0\n",
    "                for step in range((epoch*training_iters), ((epoch+1)*training_iters)):\n",
    "                    batch_x, batch_y = data_provider(self.batch_size)\n",
    "                     \n",
    "                    # Run optimization op (backprop)\n",
    "                    _, loss, lr, gradients = sess.run((self.optimizer, self.net.cost, self.learning_rate_node, self.net.gradients_node), \n",
    "                                                      feed_dict={self.net.x: batch_x,\n",
    "                                                                 self.net.y: crop_to_shape(batch_y, pred_shape),\n",
    "                                                                 self.net.keep_prob: dropout})\n",
    "\n",
    "                    if avg_gradients is None:\n",
    "                        avg_gradients = [np.zeros_like(gradient) for gradient in gradients]\n",
    "                    for i in range(len(gradients)):\n",
    "                        avg_gradients[i] = (avg_gradients[i] * (1.0 - (1.0 / (step+1)))) + (gradients[i] / (step+1))\n",
    "                        \n",
    "                    norm_gradients = [np.linalg.norm(gradient) for gradient in avg_gradients]\n",
    "                    self.norm_gradients_node.assign(norm_gradients).eval()\n",
    "                    \n",
    "                    if step % display_step == 0:\n",
    "                        self.output_minibatch_stats(sess, summary_writer, step, batch_x, crop_to_shape(batch_y, pred_shape))\n",
    "                        \n",
    "                    total_loss += loss\n",
    "\n",
    "                self.output_epoch_stats(epoch, total_loss, training_iters, lr)\n",
    "                self.store_prediction(sess, test_x, test_y, \"epoch_%s\"%epoch)\n",
    "                    \n",
    "                save_path = self.net.save(sess, save_path)\n",
    "            logging.info(\"Optimization Finished!\")\n",
    "            \n",
    "            return save_path\n",
    "        \n",
    "    def store_prediction(self, sess, batch_x, batch_y, name):\n",
    "        prediction = sess.run(self.net.predicter, feed_dict={self.net.x: batch_x,self.net.y: batch_y,self.net.keep_prob:1.})\n",
    "        pred_shape = prediction.shape\n",
    "        \n",
    "        loss = sess.run(self.net.cost, feed_dict={self.net.x: batch_x, \n",
    "                                                       self.net.y: crop_to_shape(batch_y, pred_shape), \n",
    "                                                       self.net.keep_prob: 1.})\n",
    "        \n",
    "        logging.info(\"Verification error= {:.1f}%, loss= {:.4f}\".format(error_rate(prediction,\n",
    "                                                                          crop_to_shape(batch_y,\n",
    "                                                                                             prediction.shape)),\n",
    "                                                                          loss))\n",
    "              \n",
    "        img = combine_img_prediction(batch_x, batch_y, prediction)\n",
    "        save_image(img, \"%s/%s.jpg\"%(self.prediction_path, name))\n",
    "        \n",
    "        return pred_shape\n",
    "    \n",
    "    def output_epoch_stats(self, epoch, total_loss, training_iters, lr):\n",
    "        logging.info(\"Epoch {:}, Average loss: {:.4f}, learning rate: {:.4f}\".format(epoch, (total_loss / training_iters), lr))\n",
    "    \n",
    "    def output_minibatch_stats(self, sess, summary_writer, step, batch_x, batch_y):\n",
    "        # Calculate batch loss and accuracy\n",
    "        summary_str, loss, acc, predictions = sess.run([self.summary_op, \n",
    "                                                            self.net.cost, \n",
    "                                                            self.net.accuracy, \n",
    "                                                            self.net.predicter], \n",
    "                                                           feed_dict={self.net.x: batch_x,\n",
    "                                                                      self.net.y: batch_y,\n",
    "                                                                      self.net.keep_prob: 1.})\n",
    "        summary_writer.add_summary(summary_str, step)\n",
    "        summary_writer.flush()\n",
    "        logging.info(\"Iter {:}, Minibatch Loss= {:.4f}, Training Accuracy= {:.4f}, Minibatch error= {:.1f}%\".format(step,\n",
    "                                                                                                            loss,\n",
    "                                                                                                            acc,\n",
    "                                                                                                            error_rate(predictions, batch_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Unet(channels=mydata.channels, n_class=mydata.n_class, layers=3, features_root=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(net, optimizer=\"momentum\", opt_kwargs=dict(momentum=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_path = \"./unet_trained_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = trainer.train(mydata, output_path, training_iters=50, epochs=250, display_step=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test, y_test = mydata(1)\n",
    "\n",
    "prediction = net.predict(\"./model_12_hr_250_50/model.cpkt\", x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, sharex=True, sharey=True, figsize=(12,5))\n",
    "ax[0].imshow(x_test[0,...,0], aspect=\"auto\")\n",
    "ax[1].imshow(y_test[0,...,1], aspect=\"auto\")\n",
    "mask = np.zeros_like(prediction[0,...,1],dtype=\"float32\")\n",
    "mask[prediction[0,...,1] > 0.35]=1.0\n",
    "ax[2].imshow(mask, aspect=\"auto\")\n",
    "ax[0].set_title(\"Input\")\n",
    "ax[1].set_title(\"Ground truth\")\n",
    "ax[2].set_title(\"Prediction\")\n",
    "fig.tight_layout()\n",
    "#fig.savefig(\"../docs/toy_problem.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction(x_test,y_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
